# Инструкция по запуску
## Запуск через Docker
### Предварительные требования
- Docker
- Порт 80 должен быть свободен (или можно изменить порт в файле docker-compose.yml)
### Дополнительная информация
- При запуске будет скачена модель для генерации текста, размер которой составляет 9 Гб
- Важно, чтобы у докера было достаточно ресурсов для запуска контейнера с моделью, 
рекомендуется предоставить докеру >= 16 GB RAM
- Все вычисления будут **производиться на CPU**, потому что получить сервер с GPU не представляется возможным.
При использовании GPU производительность модели увеличивается в ~15 раз (Ryzen 5 3600 vs RTX 3060).
- В базе данных создана дополнительная "тестовая" таблица, с данными клиентов, для эмуляции импорта из базы данных.
Для подключения можно использовать следующие данные:
```
host: db
port: 5432
database: g_mtg
user: postgres
password: postgres
```
1. Склонировать репозиторий
```bash
git clone https://github.com/Afaneor/lct-yakutia-backend.git lct-yakutia-backend
```
2. Перейти в папку с проектом
```bash
cd lct-yakutia-backend
```
3. запустить проект
```bash
./start.sh
```
Это скачает модель, запустит все сервисы в docker-compose
4. После запуска проекта можно воспользоваться приложением по адресу http://127.0.0.1

## Сервисы и их назначение
frontend - веб-интерфейс для взаимодействия с пользователем, написан на React + TypeScript + Ant Design.
Ссылка на репозиторий с исходным кодом - https://github.com/Afaneor/lct-yakutia-frontend.

backend - бэкенд для веб-интерфейса, написан на Python + Django.

llama - сервис для генерации текста, написан на Python + FastAPI, обертка над llama-cpp-python.


# Описание проекта
## Продукт (Project)
Продукт содержит в себе актуальную информацию о банковских продуктах.
Продукт можно удалять/добавлять/изменять только через админку. Описание 
продукта используется при формировании запроса в llm модель.

## Канал продажи (SaleChannel)
Канал продажи содержит в себе информацию о канале. Описание канала используется 
при формировании запроса в llm модель.

## Проект (Project)
Сущность, которая аккумулирует в себе информацию о продукте, каналах продажи и
содержит историю запросов по формированию маркетинговых текстов в модель.
Проект может иметь только один продукт, и разные каналы продажи.
В рамках канала продажи могут быть сформированы запросы на создание 
маркетингового предложения, а также просмотрена история о результатах
Создатель проекта становится менеджером проекта (руководителям). Менеджер
может добавлять исполнителей, и просматривать статистику.

## Канал продаж в рамках проекта (ProjectSaleChannel)
У проекта может быть несколько каналов продаж. Для канала может быть настроен 
prompt, который может быть отредактирован пользователем перед запросом в llm 
модель.

## Сотрудники проекта (ProjectUser)
У проекта может быть несколько сотрудников. В системе реализована ролевая модель.
В настоящее время есть 2 роли менеджер и исполнитель.
Отличие менеджера заключается в возможности получения статистики и назначении 
пользователей в проект.


## Данные для запроса формирования маркетингового предложения (RequestData).
Данные представляют собой модель, которая хранит в себе информацию, необходимую 
для запроса. 
В поле client_data хранится словарь, где ключ название параметра,
а значение - это значение. 
В client_data_decoding хранится словарь, где
ключ это название параметра, а значение - описание этого параметра на русском.
Поле success_type отвечает за указание того, как хорошо были сформированы 
данные по запросу. Типы позволят понять какой результат принесли сформированные 
данные (был продан продукт или никакой реакции)
Поле source_client_info позволяет понять откуда была получена информация, из
какого источника.

## Сообщение (Message).
Сообщение это объект, который хранит в себе запрос пользователя в llm модель
и ответ от нее.
Поле status также позволяет определить как хорошо было сформировано сообщение.



## Особенности.
1) Все запросы в llm модель летят через celery. Как только был получен ответ от 
llm, он вносится в БД. Также ответ вносится в argilla для дальнейшей работы с 
ним https://docs.argilla.io/en/v1.1.0/index.html
Внесение данных в argilla происходит из сигналов в момент добавления Message
2) Существует 3 апи для формирования и получения данных из llm
- POST api/llm-model/requests-data/. Позволяет сформировать 1 запрос в llm 
модель.
- POST api/llm-model/requests-data/multiple-creation. Позволяет сформировать 
множество сообщений за раз по нескольким клиентам. необходимо передавать
корректный продукт.
- POST api/llm-model/requests-data/raw-multiple-creation. Позволяет сформировать 
множество сообщений за раз по нескольким клиентам. Можно передавать описание
канала и продукта. Данные отправляются в синхронном режиме. Ответ будет получен 
только тогда, когда обработаются все запросы.
